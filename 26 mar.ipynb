{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37aba45-c87a-4ab6-b977-2416f5a41472",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans1: The differnce between the simple linear and multiple linear regression are: \n",
    "            \n",
    "            i. IN simple linear regression only one independent variabe is used to predict the dependet variable\n",
    "                while in multiple regression the more then one independent varible is used\n",
    "            ii. In simple linear regression the equation for the dependent variable is:\n",
    "                                h(x)=A1+A2xi\n",
    "                while in multiple regression the equation for the dependent variable is:\n",
    "                                h(x)=A1+A2x1+A3x3....AnXn\n",
    "                                        \n",
    "                                        where n is the numeber of independent variables.\n",
    "            iii. For example in the prediction of age and their experience in the software engineering we can use \n",
    "                 the simple linear regerssion as there is only two variable as age as independent variable and the\n",
    "                 experience as dependent variable.\n",
    "            \n",
    "                 while in ther prediction of the size of building an office where there is many independent variables\n",
    "                 such as the number of employees, location, workload and a dependent variable as size of building, we\n",
    "                 use the multiple linear regression.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b296f51-4b81-4145-9408-2227d67097c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ans2: The following are the assumptions of the linear regression:\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Ans2: The following are the assumptions of the linear regression:\n",
    "            \n",
    "            i. The data must follow the linear relation.\n",
    "            ii. There shouldn't be any multicollinearity.\n",
    "            iii. The difference between the actual and the theoritical value should follow normal distribution.\n",
    "            iv. There shouldn't be any hidden missing values.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f597da2-220d-44e0-95af-73acfc7e27c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans3: for interpreting the slope and intercept let's take and example, of the employee and the building size of office.\n",
    "    where the number of employee is the independent variable and the size of building is the depenent variable. \n",
    "    Now if we take the linear relation between the variables and found perfect fitting for the data.\n",
    "                    The fitting follows the equation: h(x) = θ1 + θ2*xi\n",
    "                    \n",
    "                                                               where θ1 = intercept\n",
    "                                                                     θ2 = slope\n",
    "    we can interpret that the slope how much the output i.e. size of building change when there is 1 employee.\n",
    "    while the intercept tells us that how much should be the size o building even when the employee is 0.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686b6b52-a301-4f55-976e-cf37b7b80b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans4: For finding the slope and the intercept in the linear regression the follwing steps must be followed:\n",
    "            \n",
    "            i. lets us take the random values of slope A2 and intercept A1.\n",
    "            ii. plot the points and find the squared mean error using the formula: (Theoritical - actual)²/n\n",
    "            iii. Use the equation of the gradient descent to find the global minima of the error.\n",
    "                            E(new) = E(old) - α * đ(J)\n",
    "                                        \n",
    "                                        where đ(J) is the  derivation of cost function\n",
    "                                              α is the learning rate\n",
    "            iv. While finding this global minima we need to change the value of A2 i.e. slope At the global minima we\n",
    "                get the value of the slope for best fit. \n",
    "            \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd83783d-1938-4303-b9e7-f05bc93066d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans5: The multiple linear regression is the type of regression in which the number of independent variables is more then\n",
    "    one i.e. the output or dependent variables is dependent on more then one variables.\n",
    "    This type of regression is used in the complex regression as in this regression the dimensions of the graph between\n",
    "    output and the input is of more then 2 and is complex to draw.\n",
    "    The output of the multiple linear regression or the dependent variable can be found by:\n",
    "                        \n",
    "                        h(x) = θ1 + θ2*x1 + θ3*x3 + θ4*x4 ...... + θn*xn\n",
    "                                                        \n",
    "                                                        where θ1 = intercept\n",
    "                                                              θn = slopes at various independent variables.\n",
    "                                                              n = number of independent variables.\n",
    "    \n",
    "    \n",
    "    While in the simple regression the independent variables is only 1 and we can simply use the simple line equation\n",
    "    for finding the output or dependent variables.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7901ce73-b5a6-4af8-b8dd-cf120b102c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ans6: The mulicollinearity is the problem in the multiple linear regeression where two or more independent variables\\n         are correlated to each other or say has the relation between them this type of correlation leads to the \\n         problem of inaccuracy in the prediction of the model.\\n         \\n         We can detect the multicollinearity by using the correlation matrix in the python which can easily created using\\n         the python function corr() in the pandas library.\\n         We can remove the correlation by adding the two or more correlated variables into one.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Ans6: The mulicollinearity is the problem in the multiple linear regeression where two or more independent variables\n",
    "         are correlated to each other or say has the relation between them this type of correlation leads to the \n",
    "         problem of inaccuracy in the prediction of the model.\n",
    "         \n",
    "         We can detect the multicollinearity by using the correlation matrix in the python which can easily created using\n",
    "         the python function corr() in the pandas library.\n",
    "         We can remove the correlation by adding the two or more correlated variables into one.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887bcd93-4b45-4c43-831e-ca5e7e8ce67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans7: The polynomial linear regression is a type of regression in which the independent variable and the dependent\n",
    "         variable when sketh on a graph then graph follow polynomial regression. We can say that the linear regression\n",
    "         is a type of polynomial regression with the degree of 1. It include all the curves which follow the perfect \n",
    "         relation.\n",
    "                                     h(x) = θ1*(x**0) + θ2*(x**1) + θ3*(x**2) .... + θn*(x**n)\n",
    "                                                             where n = degree of equation.\n",
    "         The linear regression is only limited to the straight line while the polynomial linear regression is for the all\n",
    "         type of relation.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eca57a4-dda9-4db3-8bdb-8d918187ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans8: The advantages of polynomial regerssion are: \n",
    "            \n",
    "            i. It gives the best fit fo the data irrespective of the distribution of the data.\n",
    "            ii. It givesus the non linear fit for the data with non linear distribution.\n",
    "            iii. It provide more fexiablity to the model prediction.\n",
    "        \n",
    "        The disadvantages of polynomial regression are:\n",
    "            \n",
    "            i. It can sometimes ovefit the data which can leads to the uncorrect output in the new data.\n",
    "            ii. It can be complex in when there is multiple independent variables.\n",
    "            \n",
    "        The polynomial regression can be used when the output and independent variables follow curvlinear relation \n",
    "        and vary precise fitting is needed for the model.\n",
    "            \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
